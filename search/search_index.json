{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About the Project","text":"<p>This project serves as a sample project aimed at improving knowledge about AWS and GCP infrastructure automation through the use of Terraform. In order to maximize learning, we will incorporate GitHub Actions within this project.</p> <ul> <li>Infrastructure Deployment Prerequisites</li> <li>AWS Terraform Modules</li> <li>GCP Terraform Modules</li> <li>Repository Setup</li> </ul>"},{"location":"infra-deployment-prerequisite/aws_prerequisite/","title":"AWS Deployment Prerequisite","text":"<p>To trigger the <code>terraform apply</code> command and create the configured resources within Amazon Web Services (AWS) using GitHub Actions, we utilize Open ID Connect Provider(OIDC Provider). Open ID Connect Providern enables fine-grained scoping, short-lived credentials, and minimal management overhead for authentication.</p>"},{"location":"infra-deployment-prerequisite/aws_prerequisite/#open-id-connect-provider-overview","title":"Open ID Connect Provider Overview","text":"<p>The Open ID Connect Provider (OIDC Provider) is a component used to enable the execution of the terraform apply command and the creation of resources in Amazon Web Services (AWS) through the integration with GitHub Actions. The OIDC Provider facilitates authentication and provides various benefits such as fine-grained scoping, short-lived credentials, and minimal management overhead.</p> <p>When using the OIDC Provider, it allows for secure and controlled access to AWS resources by implementing OpenID Connect (OIDC) authentication protocol. This protocol enables the exchange of identity information between the OIDC Provider and AWS. It utilizes industry-standard security practices, including OAuth 2.0, to verify and authenticate users.</p> <p>The OIDC Provider allows for the creation of fine-grained access controls by defining scopes. Scopes determine the level of access granted to users based on their roles and permissions. By using scopes, you can limit the permissions of each individual user, ensuring that they only have access to the resources and actions they need.</p> <p>Additionally, the OIDC Provider issues short-lived credentials to authenticate users. These credentials have a limited lifespan, reducing the risk of unauthorized access. This approach enhances the security of your AWS resources by regularly rotating credentials and mitigating the impact of potential security breaches.</p> <p>Furthermore, the OIDC Provider reduces management overhead by providing a centralized authentication mechanism. It eliminates the need to manage individual AWS access keys or IAM users for authentication purposes. This simplifies the authentication process and reduces the administrative burden associated with managing credentials.</p> <p>Overall, the Open ID Connect Provider offers a secure and efficient way to trigger the terraform apply command and create AWS resources within GitHub Actions. It combines fine-grained access controls, short-lived credentials, and minimal management overhead to ensure robust authentication for your infrastructure provisioning workflows.</p> <p></p>"},{"location":"infra-deployment-prerequisite/aws_prerequisite/#create-an-openid-connect-identity-provider","title":"Create an OpenID Connect Identity provider","text":"<p>The first step is to create an OpenID Connect (OIDC) identity provider in your AWS Account. This will allow Github to identify itself.</p> <ol> <li>Got to the IAM console -&gt; Identity providers</li> <li>Click Add new provider</li> <li>Select OpenID Connect</li> <li>Provider Url: <code>https://token.actions.githubusercontent.com</code> (Don't forget to click Get Thumbprint)</li> <li>Audience: <code>sts.amazonaws.com</code></li> <li>Add tags if you want to and click Add Provider</li> </ol>"},{"location":"infra-deployment-prerequisite/aws_prerequisite/#create-an-iam-role","title":"Create an IAM role","text":"<p>You now need to create a role that Github will be able to assume in order to access the resources it needs to control.</p> <ol> <li>Go back to IAM and select Roles</li> <li>Create a new Role</li> <li>Chose Web Identity, select the Identity provider you created in the previous step, and its audience.</li> <li>Click Next:Permissions</li> </ol> <p>You now need to give the role the appropriate permissions (Policies). These are the ones that Github needs in order to do whatever it has to do. This will vary based on your use case, so I will leave that up to you. Keep in mind that you should stick to the principle of least privileges.</p> <p>When that is done, give your role a name and click Create Role.</p> <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Principal\": {\n        \"Federated\": \"arn:aws:iam::1234567890:oidc-provider/token.actions.githubusercontent.com\"\n      },\n      \"Action\": \"sts:AssumeRoleWithWebIdentity\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"token.actions.githubusercontent.com:aud\": \"sts.amazonaws.com\"\n        },\n        \"StringLike\": {\n          \"token.actions.githubusercontent.com:sub\": \"repo:[your-org]/[your-repo]:*\"\n        }\n      }\n    }\n  ]\n}\n\n</code></pre>"},{"location":"infra-deployment-prerequisite/aws_prerequisite/#configure-github-action-workflow","title":"Configure Github action workflow","text":"<p>Once the above configurations are complete, you need to modify the GitHub Actions workflow file to include the following section:</p> <pre><code>- name: configure aws credentials\n  uses: aws-actions/configure-aws-credentials@v1\n  with:\n    role-to-assume: arn:aws:iam::1234567890:role/your-role-arn\n    role-duration-seconds: 900 # the ttl of the session, in seconds.\n    aws-region: us-east-1 # use your region here.\n\n</code></pre> <p>The configure AWS credentials step will use the OIDC integration to assume the given role, generate short-lived credentials, and make them available to the current job.</p>"},{"location":"infra-deployment-prerequisite/aws_prerequisite/#reference","title":"Reference","text":"<p>Securely Access Your AWS Resources From Github Actions</p>"},{"location":"infra-deployment-prerequisite/gcp_prerequisite/","title":"GCP Deployment Prerequisite","text":"<p>To trigger the <code>terraform apply</code> command and create the configured resources within Google Cloud Platform (GCP) using GitHub Actions, we utilize Web Identity Federation (WIF). Web Identity Federation enables fine-grained scoping, short-lived credentials, and minimal management overhead for authentication.</p>"},{"location":"infra-deployment-prerequisite/gcp_prerequisite/#web-identity-federation-overview","title":"Web Identity Federation Overview","text":"<p>Web Identity Federation allows you to delegate access to your GCP resources using identity providers like GitHub Actions. It leverages OpenID Connect (OIDC) to establish a trust relationship between the identity provider and GCP, allowing secure authentication and authorization.</p> <p>By setting up Web Identity Federation with GitHub Actions, you can establish a secure connection between GitHub and GCP, ensuring that the Terraform deployment process has the necessary permissions to create resources.</p> <p></p>"},{"location":"infra-deployment-prerequisite/gcp_prerequisite/#setting-up-identity-federation-for-github-actions","title":"Setting up Identity Federation for GitHub Actions","text":"<p>To use the new GitHub Actions auth action with Workload Identity Federation, you need to perform the following steps:</p> <ol> <li>Create a Workload Identity Pool:</li> </ol> <p>Use the following command to create a Workload Identity Pool:</p> <pre><code>gcloud iam workload-identity-pools create \"auto-provision-x-identity-pool\" \\\n  --project=\"${GCP_PROJECT_ID}\" \\\n  --location=\"global\" \\\n  --display-name=\"auto-provision-x-identity-pool\"\n</code></pre> <ol> <li>Create a Workload Identity Provider:</li> </ol> <p>Use the following command to create a Workload Identity Provider:</p> <pre><code>gcloud iam workload-identity-pools providers create-oidc \"auto-provision-x-oidc-provider\" \\\n  --project=\"${GCP_PROJECT_ID}\" \\\n  --location=\"global\" \\\n  --workload-identity-pool=\"auto-provision-x-identity-pool\" \\\n  --display-name=\"auto-provision-x-oidc-provider\" \\\n  --attribute-mapping=\"google.subject=assertion.sub,attribute.actor=assertion.actor,attribute.aud=assertion.aud,attribute.repository=assertion.repository,attribute.ref_type=assertion.ref_type\" \\\n  --issuer-uri=\"https://token.actions.githubusercontent.com\"\n\n</code></pre> <p>The attribute mappings map claims in the GitHub Actions JSON Web Token (JWT) to assertions that can be used to make further authentication restrictions, such as repository or GitHub username.</p> <ol> <li>Allow authentications from the Workload Identity Provider to impersonate the desired Service Account:</li> </ol> <p>Use the following command to add IAM policy binding:</p> <pre><code>gcloud iam service-accounts add-iam-policy-binding \"auto-provision-x@${GCP_PROJECT_ID}.iam.gserviceaccount.com\" \\\n  --project=\"${GCP_PROJECT_ID}\" \\\n  --role=\"roles/iam.workloadIdentityUser\" \\\n  --member=\"principalSet://iam.googleapis.com/projects/${GCP_ACCOUNT_ID}/locations/global/workloadIdentityPools/auto-provision-x-identity-pool/attribute.repository/garganshulgarg/auto-provision-x\"\n</code></pre> <p>This allows the Workload Identity Provider to authenticate as the specified Service Account.</p> <p>Once the above configurations are complete, you need to modify the GitHub Actions workflow file to include the following section:</p> <pre><code>- id: 'google-auth'\n  name: 'Authenticate to Google Cloud'\n  uses: 'google-github-actions/auth@v0.4.0'\n  with:\n    token_format: 'access_token'\n    workload_identity_provider: 'projects/${GCP_ACCOUNT_ID}/locations/global/workloadIdentityPools/auto-provision-x-identity-pool/providers/auto-provision-x-oidc-provider'\n    service_account: 'auto-provision-x@${GCP_PROJECT_ID}.iam.gserviceaccount.com'\n</code></pre> <p>This section authenticates the workflow to Google Cloud using the specified Workload Identity Provider and Service Account.</p> <p>By following these steps, you can set up Workload Identity Federations and leverage them with GitHub Actions to trigger Terraform deployments securely.</p> <p>Please ensure that you adjust the commands, configurations, and workflow file to match your specific project requirements.</p>"},{"location":"infra-deployment-prerequisite/gcp_prerequisite/#reference","title":"Reference","text":"<p>Enabling keyless authentication from GitHub Actions</p>"},{"location":"infra-deployment-prerequisite/summary/","title":"Infrastructure Deployment Prerequisites","text":"<p>Before proceeding with the infrastructure deployments, certain prerequisite steps need to be performed to ensure everything works smoothly. The deployment process involves configuring some settings within <code>Google Cloud Platform (GCP)</code> and <code>Amazon Web Services (AWS)</code> to enable the use of Workload Identity Federations instead of access keys for authentication.</p> <ul> <li>GCP Prerequisite</li> <li>AWS Prerequisite</li> </ul>"},{"location":"modules/aws/setup-apache-on-ec2/","title":"Setup apache on ec2","text":""},{"location":"modules/aws/setup-apache-on-ec2/#setup-apache-on-aws-ec2","title":"Setup Apache on AWS EC2","text":"<p>We are attempting to provision a EC2 on Amazon Web Services (AWS) using Terraform. As part of the provisioning process, we will install Apache2 on the EC2 using Terraform. Once the installation is complete, Terraform will generate a Public IP address as an output. We can use this Public IP address to validate the successful installation of Apache2</p> <pre><code>module \"aws_setup-apache-on-ec2\" {\n  source                = \"git::https://github.com/garganshulgarg/auto-provision-x.git//modules/aws/setup-apache-on-ec2/?ref=main\"\n  allowed_source_ranges = [\"0.0.0.0/0\"]\n  required_tags = {\n    \"owner\"  = \"garganshulgarg\"\n    \"repo\"   = \"auto-provision-x\"\n    \"sample\" = \"true\"\n  }\n}\n\n</code></pre>"},{"location":"modules/aws/setup-apache-on-ec2/#inputs","title":"Inputs","text":"Name Description Type Default Required allowed_source_ranges Allowed IP ranges <code>list(string)</code> n/a yes required_tags Labels which will get added to virtual machine <code>map(string)</code> <code>{}</code> no"},{"location":"modules/aws/setup-apache-on-ec2/#outputs","title":"Outputs","text":"Name Description public_ip AWS EC2 Node Public IP"},{"location":"modules/aws/summary/","title":"AWS Terraform Modules","text":"<p>This section contains all the AWS related terraform modules which we have built for our learning purpose.</p> <ul> <li>Setup Apache on EC2</li> </ul>"},{"location":"modules/gcp/setup-apache-on-vm/","title":"Setup apache on vm","text":""},{"location":"modules/gcp/setup-apache-on-vm/#setup-apache-on-gcp-vm","title":"Setup Apache on GCP VM","text":"<p>We are attempting to provision a virtual machine (VM) on Google Cloud Platform (GCP) using Terraform. As part of the provisioning process, we will install Apache2 on the VM using Terraform. Once the installation is complete, Terraform will generate a Public IP address as an output. We can use this Public IP address to validate the successful installation of Apache2</p> <pre><code>module \"gcp_setup-apache-on-vm\" {\n  source                = \"git::https://github.com/garganshulgarg/auto-provision-x.git//modules/gcp/setup-apache-on-vm/?ref=gcp-setup-apache-on-vm\"\n  name                  = \"setup-apache-on-vm\"\n  description           = \"we are setting up apache on this GCP Virtual Machine.\"\n  allowed_source_ranges = [\"0.0.0.0/0\"]\n  required_tags = {\n    \"owner\"  = \"garganshulgarg\"\n    \"repo\"   = \"auto-provision-x\"\n    \"sample\" = \"true\"\n  }\n}\n\n</code></pre>"},{"location":"modules/gcp/setup-apache-on-vm/#inputs","title":"Inputs","text":"Name Description Type Default Required allowed_source_ranges Allowed IP ranges <code>list(string)</code> n/a yes description Description of the GCP Virtual Machine <code>string</code> n/a yes name Name of the GCP Virtual Machine <code>string</code> n/a yes required_tags Labels which will get added to virtual machine <code>map(string)</code> <code>{}</code> no"},{"location":"modules/gcp/setup-apache-on-vm/#outputs","title":"Outputs","text":"Name Description public_ip GCP Public IP"},{"location":"modules/gcp/summary/","title":"GCP Terraform Modules","text":"<p>This section contains all the GCP related terraform modules which we have built for our learning purpose.</p> <ul> <li>Setup Apache on VM</li> </ul>"},{"location":"repository-setup-guide/summary/","title":"Repostory Setup Guide","text":"<p>In this section, we discuss the tools and techniques employed to establish the current repository in a standardized manner. The intention behind documenting these practices is to serve as a reference for future endeavors, as it can often be challenging to recall all the tools and techniques utilized during the initial setup.</p> <p>By detailing the best practices adopted for this repository, it becomes easier to replicate a similar structure in future projects. This not only saves time but also ensures consistency across multiple repositories. Having a centralized repository setup guide eliminates the need to rediscover or relearn the practices every time a new project is initiated.</p> <p>By referring back to this section, you can easily identify and implement the best practices that were successfully employed during the establishment of the current repository. This approach fosters efficiency and maintains a standardized structure, contributing to the overall organization and management of projects in the future.</p> <ul> <li>Husky Setup</li> <li>Mkdocs Setup</li> </ul>"},{"location":"repository-setup-guide/husky-setup/husky-local-setup/","title":"Local Setup of Husky","text":""},{"location":"repository-setup-guide/husky-setup/husky-local-setup/#prerequisite","title":"Prerequisite","text":"<p>Before setting up Husky, ensure that your <code>npm</code> version is greater than <code>7.0.0</code>. You can check your npm version by running the command <code>npm -v</code> in your terminal or command prompt.</p>"},{"location":"repository-setup-guide/husky-setup/husky-local-setup/#installing-husky","title":"Installing Husky","text":"<p>To install Husky and set up the local configuration, follow these steps:</p> <ol> <li> <p>Open your terminal or command prompt.</p> </li> <li> <p>Navigate to your project's root directory.</p> </li> <li> <p>Run the following command to install Husky:</p> </li> </ol> <pre><code>npx husky-init &amp;&amp; npm install\n</code></pre> <ol> <li> <p>This command will initialize Husky in your project and install the necessary dependencies.</p> </li> <li> <p>For more detailed information and troubleshooting, you can refer to the official Husky documentation.</p> </li> </ol>"},{"location":"repository-setup-guide/husky-setup/husky-local-setup/#configuring-commitlint","title":"Configuring Commitlint","text":"<p>Commitlint can be configured to enforce the conventional commit format and validate commit messages. Follow these steps to set up Commitlint:</p> <ol> <li> <p>Open your terminal or command prompt.</p> </li> <li> <p>Navigate to your project's root directory.</p> </li> <li> <p>Run the following command to install Commitlint and Husky as dev dependencies:</p> </li> </ol> <pre><code>npm install --save-dev @commitlint/cli husky\n</code></pre> <ol> <li> <p>Create a file named <code>commitlint.config.js</code> in your project's root directory.</p> </li> <li> <p>Open the <code>commitlint.config.js</code> file in a text editor.</p> </li> <li> <p>Add the following configuration to enable the conventional commit format:</p> </li> </ol> <pre><code>module.exports = {\n  extends: ['@commitlint/config-conventional'],\n};\n</code></pre> <ol> <li>Save the changes to the <code>commitlint.config.js</code> file.</li> </ol>"},{"location":"repository-setup-guide/husky-setup/husky-local-setup/#testing-the-configuration","title":"Testing the Configuration","text":"<p>To ensure that the Commitlint and Husky configuration is working correctly, follow these steps:</p> <ol> <li> <p>Create a new commit or amend an existing commit in your repository.</p> </li> <li> <p>Before the commit is finalized, Commitlint will enforce the conventional commit format and validate the commit message.</p> </li> <li> <p>If the commit message does not adhere to the specified format, Commitlint will throw an error and prevent the commit from being made.</p> </li> </ol> <p>By following these steps, you can set up Husky locally, configure Commitlint to enforce conventional commit messages, and validate commit messages before finalizing the commit. This helps maintain consistent commit message formats and improves the overall quality of commits in your project.</p>"},{"location":"repository-setup-guide/husky-setup/summary/","title":"Husky Setup","text":"<p>Husky improves your commits and more \ud83d\udc36 woof!</p> <p>Husky helps us do more things along with git commands. For example, we can run <code>npm test</code> in <code>pre-commit</code>phase and do something else in <code>post-commit</code> phase</p> <ul> <li>Local Setup of Husky</li> </ul>"},{"location":"repository-setup-guide/mkdocs-setup/gh-pages-setup/","title":"Setting up GitHub Pages for MkDocs","text":"<p>To set up GitHub Pages for MkDocs, you will need to create a GitHub Action that automates the process of pushing your code to the <code>gh-pages</code> branch of your repository. The GitHub Action will execute the following command:</p> <pre><code>mkdocs build\nmkdocs gh-deploy --force\n</code></pre> <p>This command will generate all the relevant files and commit the code to the repository.</p> <p>For more details on the GitHub Action setup, refer to the file <code>.github/workflows/deploy-docs.yml</code> within the same repository.</p>"},{"location":"repository-setup-guide/mkdocs-setup/mkdocs-local-setup/","title":"Local Setup of MkDocs","text":"<p>This documentation provides instructions for setting up MkDocs locally on your system.</p>"},{"location":"repository-setup-guide/mkdocs-setup/mkdocs-local-setup/#prerequisites","title":"Prerequisites","text":"<p>Before you proceed with the installation, make sure you have the following prerequisites:</p> <ol> <li>Python (already installed on most systems)</li> <li>Terminal or Command Prompt</li> </ol>"},{"location":"repository-setup-guide/mkdocs-setup/mkdocs-local-setup/#installation-steps","title":"Installation Steps","text":"<p>Follow the steps below to set up MkDocs locally:</p> <ol> <li> <p>Open the Terminal or Command Prompt.</p> </li> <li> <p>Install Python using Homebrew (for macOS users):</p> </li> </ol> <pre><code>brew install python\n</code></pre> <ol> <li>Verify the installation by checking the Python and pip versions:</li> </ol> <pre><code>python3 --version\npip3 --version\n</code></pre> <ol> <li> <p>Restart the Terminal or Command Prompt.</p> </li> <li> <p>Install MkDocs using pip:</p> </li> </ol> <pre><code>pip3 install mkdocs\nRestart the Terminal or Command Prompt.\n</code></pre> <ol> <li>Create a sample <code>mkdocs.yml</code> file and a docs folder in your project directory. You can create the <code>mkdocs.yml</code> file by running the following command:</li> </ol> <pre><code>touch mkdocs.yml\n</code></pre> <ol> <li> <p>Copy the content of mkdocs.yml from the file present at the root of this code repository.</p> </li> <li> <p>Install the following plugins locally using pip:</p> </li> </ol> <pre><code>pip3 install mkdocs-material\npip3 install mkdocs-awesome-pages-plugin\npip3 install mkdocs_include_markdown_plugin\npip3 install mkdocs-mermaid2-plugin\npip3 install mkdocs-literate-nav\n</code></pre>"},{"location":"repository-setup-guide/mkdocs-setup/mkdocs-local-setup/#running-mkdocs","title":"Running MkDocs","text":"<p>To run MkDocs and preview your documentation locally, use the following command in the Terminal or Command Prompt:</p> <pre><code>mkdocs serve\n</code></pre> <p>This will start a local development server, and you can access your documentation by opening a web browser and navigating to http://localhost:8000.</p> <p>You have now successfully set up MkDocs locally on your system. You can start editing your Markdown files in the docs folder and customize the configuration in the mkdocs.yml file as needed.</p>"},{"location":"repository-setup-guide/mkdocs-setup/summary/","title":"Mkdocs Setup","text":"<ul> <li>Local Setup</li> <li>Github Pages Setup</li> </ul> <p>We have implemented Mkdocs, a Python-based static site generator, as the documentation framework for our repository. Mkdocs allows us to create clean and professional-looking documentation sites from simple Markdown files.</p> <p>To set up Mkdocs for our repository, we followed the following steps:</p> <p>Install Mkdocs: We installed Mkdocs by using <code>pip</code>, the package installer for Python. This enabled us to access the Mkdocs command-line interface (CLI) and utilize its features.</p> <p>Configuration: We created a <code>mkdocs.yml</code> configuration file in the root directory of our repository. This file serves as the central configuration point for our Mkdocs project. It allows us to specify various settings, such as the site name, theme, navigation structure, and additional customizations.</p> <p>Documentation Structure: We organized our documentation content using Markdown files. Mkdocs automatically converts these Markdown files into HTML pages, making it easy to write and maintain our documentation.</p> <p>Customization: Mkdocs provides a range of themes and customization options to tailor the appearance of our documentation site. We explored different themes and selected the one that best suited our needs. Additionally, we customized the theme to match our branding and improve the user experience.</p> <p>Preview and Local Development: To view our documentation site during the development phase, we utilized the Mkdocs built-in development server. This allowed us to preview the site locally and make necessary adjustments before publishing it.</p> <p>By implementing Mkdocs and following these steps, we have created a comprehensive and user-friendly documentation framework for our repository. It enables us to efficiently document our code, project guidelines, and other relevant information in a clear and organized manner.</p>"}]}